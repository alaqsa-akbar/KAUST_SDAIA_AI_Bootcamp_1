{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:35:16.398129Z",
     "start_time": "2024-01-11T16:35:16.395195Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1704988653828,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "BCpQaqwoH2Pk"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:35:21.387029Z",
     "start_time": "2024-01-11T16:35:17.086686Z"
    },
    "id": "HBuuF9MJKjoe"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)\n",
    "\n",
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install matplotlib\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:35:23.310818Z",
     "start_time": "2024-01-11T16:35:23.162485Z"
    },
    "executionInfo": {
     "elapsed": 12717,
     "status": "ok",
     "timestamp": 1704988681107,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "gtV7omCIKq0K"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _C: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MNIST\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[0;32m      4\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      5\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001b[0;32m      4\u001b[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001b[0;32m      5\u001b[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, device, dtype\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\parameter.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disabled_torch_function_impl\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Metaclass to combine _TensorMeta and the instance check override for Parameter.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _C: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image, resize\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBNjc2JpLGIa"
   },
   "source": [
    "# Sign Langauge Problem:\n",
    "\n",
    "## Intution: The AI is so powrful and important because of its various applications on most if not all the different fields. As a result, we want to help in solving the issue of not understanding sign languages.\n",
    "\n",
    "## - This notebook contains a detailed implementaiton of a NN uisng Pytorch.\n",
    "\n",
    "### 1. Data set Details:\n",
    "\n",
    "- The provided data set is ArASL (Arabic Alphabets Sign Language Dataset). It is as its name says, an arabic sighn langauge for Arabic alphabet. It has a total of 54049 images and their corrssponding labels.\n",
    "\n",
    "### 2. Size of data:\n",
    "- Length of train_dataset is 43239,\n",
    "- Length of val_dataset is 10810\n",
    "\n",
    "### 3. Labels representations:\n",
    "- Each sample has a label, which can be one of the 32 classes.\n",
    "It consist of 32 classes for the alphabet.\n",
    "- The classes values are integers from 0 up to 31.\n",
    "\n",
    "\n",
    "### 4. The mapping details:\n",
    "\n",
    "- Each number represents a charcter. You can see the dictionary in the variable \"mapping\".\n",
    "\n",
    "<br/>\n",
    "-- You can see the mapping in the following:\n",
    "\n",
    "0: 'seen', 1: 'zay', 2: 'aleff', 3: 'dal', 4: 'ta', 5: 'yaa', 6: 'fa', 7: 'ya', 8: 'khaa', 9: 'nun', 10: 'ha', 11: 'toot', 12: 'taa', 13: 'ra', 14: 'kaaf', 15: 'jeem', 16: 'laam', 17: 'la', 18: 'dhad', 19: 'dha', 20: 'waw', 21: 'meem', 22: 'al', 23: 'sheen', 24: 'haa', 25: 'thaa', 26: 'saad', 27: 'ghain', 28: 'ain', 29: 'thal', 30: 'gaaf', 31: 'bb'\n",
    "\n",
    "### 5. Refrence:\n",
    "Latif, G., Mohammad, N., Alghazo, J., AlKhalaf, R., & AlKhalaf, R. (2019). ARASL: Arabic Alphabets Sign Language Dataset. *Data in Brief*, 23, 103777. https://doi.org/10.1016/j.dib.2019.103777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw5z1ZSoLlh1"
   },
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "### Run the following cells to download the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.686Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4437,
     "status": "ok",
     "timestamp": 1704988851143,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "AqQxPwbp7TfV",
    "outputId": "7ffdcaa1-06e3-4967-d343-39b1171eeae5"
   },
   "outputs": [],
   "source": [
    "!gdown https://data.mendeley.com/public-files/datasets/y7pckrw6z2/files/1efa0d6b-4d7f-4f58-9584-08f0488279ee/file_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.688Z"
    },
    "executionInfo": {
     "elapsed": 16856,
     "status": "ok",
     "timestamp": 1704988869496,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "yfnx8Ebf7pTT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    try:\n",
    "        # Get the list of files and subdirectories in the folder\n",
    "        for item in os.listdir(folder_path):\n",
    "            item_path = os.path.join(folder_path, item)\n",
    "\n",
    "            # If it's a file, delete it\n",
    "            if os.path.isfile(item_path):\n",
    "                os.remove(item_path)\n",
    "            # If it's a directory, recursively call delete_folder\n",
    "            elif os.path.isdir(item_path):\n",
    "                delete_folder(item_path)\n",
    "\n",
    "        # Remove the empty folder\n",
    "        os.rmdir(folder_path)\n",
    "        print(f\"Folder '{folder_path}' and its contents deleted successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder '{folder_path}' not found.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission error: Unable to delete folder '{folder_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "delete_folder('ArASL_Database_54K_Final')\n",
    "\n",
    "!unzip file_downloaded\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWb17ZPBAWvP"
   },
   "source": [
    "## Just run these two cells. You are not supposed to explore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.689Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "error",
     "timestamp": 1704988888355,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "6sjyA1C1E5ik",
    "outputId": "dc2ae95c-1e10-4bcc-da59-1488a74852e6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_folders_and_create_mapping(folder_path):\n",
    "    # Get the list of folders in the specified path\n",
    "    folders = [folder for folder in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, folder))]\n",
    "\n",
    "    # Create a mapping from original folder names to numbers\n",
    "    folder_mapping = {folder: i for i, folder in enumerate(folders)}\n",
    "\n",
    "    # Rename the folders in-place and store the original names in the mapping\n",
    "    for original_folder, number in folder_mapping.items():\n",
    "        new_folder_name = str(number)\n",
    "        new_folder_path = os.path.join(folder_path, new_folder_name)\n",
    "\n",
    "        # Rename the folder\n",
    "        os.rename(os.path.join(folder_path, original_folder), new_folder_path)\n",
    "\n",
    "    return folder_mapping\n",
    "\n",
    "folder_path = 'ArASL_Database_54K_Final'\n",
    "\n",
    "# Create the folder mapping and rename folders\n",
    "mapping = rename_folders_and_create_mapping(folder_path)\n",
    "\n",
    "# Print the folder mapping\n",
    "print(\"Folder Mapping:\")\n",
    "print(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.690Z"
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1704988893069,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "Efxefg5j94pO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_folder, transform=None, target_size=(28, 28)):\n",
    "        self.root_folder = root_folder\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # Get the list of image files\n",
    "        self.image_files = []\n",
    "        self.image_labels = []\n",
    "\n",
    "        for root, dirs, files in os.walk(root_folder):\n",
    "            for file in files:\n",
    "                if file.lower().endswith('.jpg'):\n",
    "                    self.image_files.append(os.path.join(root, file))\n",
    "                    self.image_labels.append(int(os.path.basename(root)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        label = self.image_labels[idx]\n",
    "\n",
    "        # Convert label to tensor\n",
    "        # print(\"Label\", label, type(label))\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        # Open the image\n",
    "        with Image.open(img_path) as img:\n",
    "            # Convert the image to grayscale\n",
    "            img = img.convert('L')\n",
    "\n",
    "            # Resize the image\n",
    "            img = img.resize(self.target_size)\n",
    "\n",
    "            # Apply additional transformations if specified\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            return (img, label)\n",
    "\n",
    "# Define the root folder and output folder\n",
    "root_folder_path = 'ArASL_Database_54K_Final'\n",
    "\n",
    "\n",
    "# Define transformations (resize to 28x28 and convert to tensor)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "custom_dataset = CustomDataset(root_folder_path, transform=data_transform)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the size of the training and validation sets\n",
    "total_size = len(custom_dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "val_size = total_size - train_size  # 20% for validation\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n",
    "\n",
    "mapping = {v:k for k,v in mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObDvaInfAdBJ"
   },
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmA6buxlh9XI"
   },
   "source": [
    "#### Here is the mapping for each class and its encoding. In addition to the train_dataset and val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.691Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1704988962952,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "60ugrf0DMF2N",
    "outputId": "384999a0-652f-4e04-f422-a19ac534ef1c"
   },
   "outputs": [],
   "source": [
    "train_dataset # Contains the training ArASL_Database_54K_Final dataset (80%)\n",
    "\n",
    "val_dataset  # Contains the validating ArASL_Database_54K_Final dataset (20%)\n",
    "\n",
    "\n",
    "print(\"The mapping between the letters and the encoding: \\n\", mapping)\n",
    "\n",
    "# Check the lengths of train_dataset and val_dataset.\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.692Z"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1704988966702,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "Oj4XUGKBQmwH"
   },
   "outputs": [],
   "source": [
    "batch_size = 64 # To group each k samples together.\n",
    "\n",
    "# DataLoaders simplify the job of grouping the samples into batches.\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # no need to shuffle validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bw5HNZeQ7Gc"
   },
   "source": [
    "## Let's visualize an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.693Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1704989470754,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "kXxCJ5pQQ5jw",
    "outputId": "47ef64e3-aef8-4d6e-8c50-8ce986d771e8"
   },
   "outputs": [],
   "source": [
    "random_img_idx = 30 # Write any random index (between 0 and 59999)\n",
    "\n",
    "image = train_dataset[random_img_idx][0]  # 0 for image part in (image, label) tuple.\n",
    "label = train_dataset[random_img_idx][1]  # 1 for label part\n",
    "\n",
    "print(\"The image label:\", label.item(), mapping[label.item()])\n",
    "\n",
    "plt.imshow(image.reshape(image.shape[1], image.shape[1]), cmap='gray')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wATuG1cPwms"
   },
   "source": [
    "### Create a loop to show 10 different images ranodmly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.694Z"
    },
    "id": "SIHE3pWlPvvK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for _ in range(10):\n",
    "    random_img_idx = np.random.randint(len(train_dataset))\n",
    "\n",
    "    image = train_dataset[random_img_idx][0]\n",
    "    label = train_dataset[random_img_idx][1]\n",
    "    print(\"The image label:\", label.item(), mapping[label.item()])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(image.reshape(image.shape[1], image.shape[1]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvysz1ZnSh7f"
   },
   "source": [
    "### Create a NN uisng Pytorch. Then, train the model. Play with the layers to get the best model on the validation data, try to reach a 90% accuracy. At least, make 3 different layers. Also, try different activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.695Z"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1704989710928,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "5G7ib-G0LTC1"
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(ni, nh)\n",
    "        self.layer2 = nn.Linear(nh, nh//4)\n",
    "        self.layer3 = nn.Linear(nh//4, no)\n",
    "\n",
    "        self.hidden_activation = nn.ReLU()\n",
    "        self.out_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_activation(self.layer1(x))\n",
    "        x = self.hidden_activation(self.layer2(x))\n",
    "        x = self.out_activation(self.layer3(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.696Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1704989858514,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "pGJofxjzSO73",
    "outputId": "1017f108-df85-4212-c9e8-9218f26ca1d0"
   },
   "outputs": [],
   "source": [
    "LENGTH = 48\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = NN(LENGTH * LENGTH, 1024, 32)\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T16:34:30.697Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "executionInfo": {
     "elapsed": 72046,
     "status": "error",
     "timestamp": 1704990758746,
     "user": {
      "displayName": "Theivze",
      "userId": "05192969213089984796"
     },
     "user_tz": -180
    },
    "id": "iuW-tSo9ToCK",
    "outputId": "ba11f261-31d2-4388-ecea-abbd9bbc8990"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch_num in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoch_losses = 0\n",
    "    val_epoch_losses = 0\n",
    "    correct_pred = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.view(-1, LENGTH * LENGTH).to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        batch_y_probs = model(batch_x)\n",
    "\n",
    "        loss = loss_func(batch_y_probs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses += loss.item() * len(batch_y)\n",
    "\n",
    "    epoch_loss = epoch_losses/len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for val_batch_x, val_batch_y in val_loader:\n",
    "            val_batch_x = val_batch_x.view(-1, LENGTH*LENGTH).to(device)\n",
    "            val_batch_y = val_batch_y.to(device)\n",
    "\n",
    "            val_batch_y_probs = model(val_batch_x)\n",
    "\n",
    "            loss = loss_func(val_batch_y_probs, val_batch_y)\n",
    "\n",
    "            val_batch_y_preds = val_batch_y_probs.argmax(dim=1)\n",
    "\n",
    "            val_epoch_losses += loss.item() * len(val_batch_y)\n",
    "            correct_pred += (val_batch_y==val_batch_y_preds).sum().item()\n",
    "        val_epoch_loss = val_epoch_losses/len(val_loader.dataset)\n",
    "        val_losses.append(val_epoch_loss)\n",
    "    print(f'Epoch: {epoch_num}, train_loss={epoch_loss}, val_loss={val_epoch_loss}. labelled {correct_pred}/{len(val_loader.dataset)} correctly ({correct_pred/len(val_loader.dataset)*100}% accuracy)')\n",
    "print(f'Training complete on device {device}. Change device variable and run again to see the difference.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qWb17ZPBAWvP"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
